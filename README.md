# back-llm
Minimal code to run a llama-like model with an oobabooga compatible api

Work with python http.server. Do not use in production.

Can support AES with a preshared key (export PSK in .env) so you can use crypted api without using a certificate.

Easy to learn and customize.
